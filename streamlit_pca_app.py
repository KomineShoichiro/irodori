import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import io
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.pdfgen import canvas
from reportlab.lib import colors
import tempfile
import base64
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont

# matplotlib å…¨ä½“è¨­å®šï¼ˆè«–æ–‡ä½“è£ï¼‰
plt.rcParams.update({
    'font.size': 24,
    'axes.titlesize': 24,
    'axes.labelsize': 24,
    'xtick.labelsize': 24,
    'ytick.labelsize': 24,
    'legend.fontsize': 16,
    'xtick.direction': 'in',
    'ytick.direction': 'in',
    'xtick.top': True,
    'ytick.right': True,
})

# ReportLab æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆç™»éŒ²
try:
    pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
    pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
except Exception:
    pass

st.set_page_config(page_title="irodori è§£æã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸ“Š ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")
st.markdown("---")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'report_title' not in st.session_state:
    st.session_state.report_title = "PCAåˆ†æãƒ¬ãƒãƒ¼ãƒˆ"
if 'author_name' not in st.session_state:
    st.session_state.author_name = ""
if 'analysis_date' not in st.session_state:
    st.session_state.analysis_date = None
if 'mean_spectrum_notes' not in st.session_state:
    st.session_state.mean_spectrum_notes = ""
if 'pca_scatter_notes' not in st.session_state:
    st.session_state.pca_scatter_notes = ""
if 'loading_notes' not in st.session_state:
    st.session_state.loading_notes = ""
if 'overall_conclusion' not in st.session_state:
    st.session_state.overall_conclusion = ""

def load_and_prepare_data(df):
    label_col = None
    for col in df.columns:
        if col.lower() in ['label', 'class', 'category', 'group']:
            label_col = col
            break

    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()

    if label_col:
        labels = df[label_col].values
        feature_columns = [col for col in numeric_columns if col != label_col]
    else:
        labels = None
        feature_columns = numeric_columns

    features = df[feature_columns].values
    return features, labels, feature_columns, label_col

def create_mean_spectrum_plot(features, labels, feature_columns, label_col):
    """ãƒ©ãƒ™ãƒ«ã”ã¨ã®å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    if labels is None:
        return None

    fig, ax = plt.subplots(figsize=(12, 8))

    unique_labels = np.unique(labels)
    colors = plt.cm.tab10(np.linspace(0, 1, max(10, len(unique_labels))))
    markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h']

    for i, label in enumerate(unique_labels):
        mask = labels == label
        mean_spectrum = np.mean(features[mask], axis=0)
        std_spectrum = np.std(features[mask], axis=0)

        # å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå¤ªç·šï¼‰
        ax.plot(
            range(len(feature_columns)), mean_spectrum,
            marker=markers[i % len(markers)], linewidth=2.5, markersize=6,
            color=colors[i % len(colors)], label=f'ã‚¯ãƒ©ã‚¹ {label}'
        )

        # æ¨™æº–åå·®ã®ç¯„å›²ã‚’å¡—ã‚Šã¤ã¶ã—
        ax.fill_between(
            range(len(feature_columns)),
            mean_spectrum - std_spectrum,
            mean_spectrum + std_spectrum,
            alpha=0.15, color=colors[i % len(colors)]
        )

    ax.set_xlabel('æ³¢é•· (nm)', fontsize=24)
    ax.set_ylabel('å¼·åº¦ (arb. unit)', fontsize=24)

    # Xè»¸ã®ãƒ©ãƒ™ãƒ«ã‚’è¨­å®š
    ax.set_xticks(range(len(feature_columns)))
    ax.set_xticklabels(feature_columns, rotation=45, ha='right')

    ax.grid(True, alpha=0.3, axis='y')
    ax.tick_params(axis='both', which='major', direction='in', top=True, right=True, length=8, width=1.2, labeltop=False, labelright=False)
    ax.tick_params(axis='both', which='minor', direction='in', top=True, right=True, length=4, width=1.0)
    ax.minorticks_on()
    ax.legend(frameon=True, loc='best', fontsize=16)

    return fig

def perform_pca_analysis(features):
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)

    # ç¬¬1ã€œç¬¬3ä¸»æˆåˆ†ã¾ã§ç®—å‡º
    pca = PCA(n_components=3)
    pca_result = pca.fit_transform(features_scaled)
    explained_variance_ratio = pca.explained_variance_ratio_

    return pca_result, pca, explained_variance_ratio

def create_pca_scatter_plot(pca_result, labels, explained_variance_ratio, dims=(0, 1)):
    fig, ax = plt.subplots(figsize=(10, 8))

    x_idx, y_idx = dims
    if labels is not None:
        unique_labels = np.unique(labels)
        colors = plt.cm.tab10(np.linspace(0, 1, max(10, len(unique_labels))))
        markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h']

        for i, label in enumerate(unique_labels):
            mask = labels == label
            ax.scatter(
                pca_result[mask, x_idx], pca_result[mask, y_idx],
                c=[colors[i % len(colors)]], marker=markers[i % len(markers)], s=100, alpha=0.9,
                edgecolors='black', linewidth=0.5, label=f'ã‚¯ãƒ©ã‚¹ {label}'
            )
    else:
        ax.scatter(
            pca_result[:, x_idx], pca_result[:, y_idx],
            c='tab:blue', marker='o', s=100, alpha=0.9,
            edgecolors='black', linewidth=0.5
        )

    ax.set_xlabel(f'ç¬¬{x_idx+1}ä¸»æˆåˆ† (èª¬æ˜ç‡{explained_variance_ratio[x_idx]:.1%})', fontsize=24)
    ax.set_ylabel(f'ç¬¬{y_idx+1}ä¸»æˆåˆ† (èª¬æ˜ç‡{explained_variance_ratio[y_idx]:.1%})', fontsize=24)

    # ä½“è£ï¼ˆè«–æ–‡ä½“è£ï¼‰
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.tick_params(axis='both', which='major', direction='in', top=True, right=True, length=8, width=1.2, labeltop=False, labelright=False)
    ax.tick_params(axis='both', which='minor', direction='in', top=True, right=True, length=4, width=1.0)
    ax.minorticks_on()
    # ä¸Šä¸‹å³ã®ç›®ç››ã¯å‡ºã™ãŒã€æ•°å­—ã¯è¡¨ç¤ºã—ãªã„
    # ã‚¿ã‚¤ãƒˆãƒ«ã¯ä¸è¦

    if labels is not None:
        ax.legend(frameon=True, loc='best', fontsize=24)

    return fig

def create_loading_plot(pca, feature_columns, pc_index: int = 0):
    fig, ax = plt.subplots(figsize=(12, 6))

    pc1_loadings = pca.components_[pc_index]

    try:
        feature_importance = list(zip(feature_columns, pc1_loadings))
        feature_importance.sort(key=lambda x: int(x[0]))
    except:
        feature_importance = list(zip(feature_columns, pc1_loadings))

    sorted_features = [item[0] for item in feature_importance]
    sorted_loadings = [item[1] for item in feature_importance]

    ax.plot(
        range(len(sorted_features)), sorted_loadings,
        marker='o', linewidth=2.5, markersize=6, color='tab:blue'
    )

    for i, loading in enumerate(sorted_loadings):
        if loading < 0:
            ax.plot(i, loading, 'o', markersize=6, color='red')

    ax.set_xlabel('æ³¢é•· (nm)', fontsize=24)
    ax.set_ylabel(f'ç¬¬{pc_index+1}ä¸»æˆåˆ†è² è·ç‡', fontsize=24)

    ax.set_xticks(range(len(sorted_features)))
    ax.set_xticklabels(sorted_features, rotation=45, ha='right')

    ax.grid(True, alpha=0.3, axis='y')
    mean_loading = np.mean(sorted_loadings)
    ax.axhline(y=mean_loading, color='black', linestyle='-', linewidth=1.2, alpha=0.7)

    max_abs_loading = max(abs(min(sorted_loadings)), abs(max(sorted_loadings)))
    y_margin = max_abs_loading * 0.2
    ax.set_ylim(mean_loading - max_abs_loading - y_margin, mean_loading + max_abs_loading + y_margin)

    for i, loading in enumerate(sorted_loadings):
        ax.text(
            i, loading + (0.005 if loading >= 0 else -0.005),
            f'{loading:.3f}', ha='center', va='bottom' if loading >= 0 else 'top',
            fontsize=14
        )

    # ä½“è£ï¼ˆè«–æ–‡ä½“è£ï¼‰
    ax.tick_params(axis='both', which='major', direction='in', top=True, right=True, length=8, width=1.2, labeltop=False, labelright=False)
    ax.tick_params(axis='both', which='minor', direction='in', top=True, right=True, length=4, width=1.0)
    ax.minorticks_on()
    # å‰¯è»¸ï¼ˆä¸Šãƒ»å³ï¼‰
    ax.secondary_xaxis('top')
    ax.secondary_yaxis('right')
    # ã‚¿ã‚¤ãƒˆãƒ«ã¯ä¸è¦

    return fig

def create_pdf_report(report_data):
    """PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    story = []

    # ã‚¹ã‚¿ã‚¤ãƒ«ã®è¨­å®š
    styles = getSampleStyleSheet()
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        spaceAfter=30,
        alignment=1,  # ä¸­å¤®æƒãˆ
        fontName='HeiseiKakuGo-W5'
    )
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontSize=16,
        spaceAfter=12,
        spaceBefore=20,
        fontName='HeiseiKakuGo-W5'
    )
    normal_style = styles['Normal']
    normal_style.fontName = 'HeiseiKakuGo-W5'

    # ã‚¿ã‚¤ãƒˆãƒ«
    story.append(Paragraph(report_data['title'], title_style))
    story.append(Spacer(1, 20))

    # åŸºæœ¬æƒ…å ±
    if report_data['author']:
        story.append(Paragraph(f"<b>ä½œæˆè€…:</b> {report_data['author']}", normal_style))
    if report_data['date']:
        story.append(Paragraph(f"<b>ä½œæˆæ—¥:</b> {report_data['date']}", normal_style))
    story.append(Spacer(1, 20))

    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    story.append(Paragraph("ãƒ‡ãƒ¼ã‚¿æ¦‚è¦", heading_style))
    story.append(Paragraph(f"<b>ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:</b> {report_data['data_shape']}", normal_style))
    story.append(Paragraph(f"<b>ç‰¹å¾´é‡æ•°:</b> {report_data['feature_count']}", normal_style))
    if report_data['label_info']:
        story.append(Paragraph(f"<b>ãƒ©ãƒ™ãƒ«æƒ…å ±:</b> {report_data['label_info']}", normal_style))
    story.append(Spacer(1, 20))

    # PCAçµæœï¼ˆè¦‹å‡ºã—é †ã®æ•´ç†ï¼‰
    story.append(Paragraph("PCAåˆ†æçµæœã®è¦ç´„", heading_style))
    story.append(Paragraph(f"<b>ç¬¬1ä¸»æˆåˆ†å¯„ä¸ç‡:</b> {report_data['pc1_variance']:.1%}", normal_style))
    story.append(Paragraph(f"<b>ç¬¬2ä¸»æˆåˆ†å¯„ä¸ç‡:</b> {report_data['pc2_variance']:.1%}", normal_style))
    if 'pc3_variance' in report_data and report_data['pc3_variance'] is not None:
        story.append(Paragraph(f"<b>ç¬¬3ä¸»æˆåˆ†å¯„ä¸ç‡:</b> {report_data['pc3_variance']:.1%}", normal_style))
    story.append(Paragraph(f"<b>ç´¯ç©å¯„ä¸ç‡:</b> {report_data['total_variance']:.1%}", normal_style))
    story.append(Spacer(1, 20))

    # ã‚°ãƒ©ãƒ•ã¨è€ƒå¯Ÿ
    if report_data['mean_spectrum_fig']:
        story.append(Paragraph("ãƒ©ãƒ™ãƒ«ã”ã¨ã®å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«", heading_style))
        story.append(Image(report_data['mean_spectrum_fig'], width=6*inch, height=4*inch))
        if report_data['mean_spectrum_notes']:
            story.append(Paragraph(f"<b>è€ƒå¯Ÿ:</b> {report_data['mean_spectrum_notes']}", normal_style))
        story.append(Spacer(1, 20))

    story.append(Paragraph("PCAæ•£å¸ƒå›³ (PC1 vs PC2)", heading_style))
    story.append(Image(report_data['pca_scatter_fig'], width=6*inch, height=4*inch))
    if report_data['pca_scatter_notes']:
        story.append(Paragraph(f"<b>è€ƒå¯Ÿ:</b> {report_data['pca_scatter_notes']}", normal_style))
    story.append(Spacer(1, 20))

    if 'pca_scatter_fig_pc13' in report_data and report_data['pca_scatter_fig_pc13'] is not None:
        story.append(Paragraph("PCAæ•£å¸ƒå›³ (PC1 vs PC3)", heading_style))
        story.append(Image(report_data['pca_scatter_fig_pc13'], width=6*inch, height=4*inch))
        story.append(Spacer(1, 20))

    if 'pca_scatter_fig_pc23' in report_data and report_data['pca_scatter_fig_pc23'] is not None:
        story.append(Paragraph("PCAæ•£å¸ƒå›³ (PC2 vs PC3)", heading_style))
        story.append(Image(report_data['pca_scatter_fig_pc23'], width=6*inch, height=4*inch))
        story.append(Spacer(1, 20))

    story.append(Paragraph("è² è·ç‡ã‚°ãƒ©ãƒ• (PC1)", heading_style))
    story.append(Image(report_data['loading_fig'], width=6*inch, height=3*inch))
    if report_data['loading_notes']:
        story.append(Paragraph(f"<b>è€ƒå¯Ÿ:</b> {report_data['loading_notes']}", normal_style))
    story.append(Spacer(1, 20))

    if 'loading_fig_pc2' in report_data and report_data['loading_fig_pc2'] is not None:
        story.append(Paragraph("è² è·ç‡ã‚°ãƒ©ãƒ• (PC2)", heading_style))
        story.append(Image(report_data['loading_fig_pc2'], width=6*inch, height=3*inch))
        story.append(Spacer(1, 20))

    if 'loading_fig_pc3' in report_data and report_data['loading_fig_pc3'] is not None:
        story.append(Paragraph("è² è·ç‡ã‚°ãƒ©ãƒ• (PC3)", heading_style))
        story.append(Image(report_data['loading_fig_pc3'], width=6*inch, height=3*inch))
        story.append(Spacer(1, 20))

    # ç·åˆè€ƒå¯Ÿ
    if report_data['overall_conclusion']:
        story.append(Paragraph("ç·åˆè€ƒå¯Ÿ", heading_style))
        story.append(Paragraph(report_data['overall_conclusion'], normal_style))
        story.append(Spacer(1, 20))

    # ç‰¹å¾´é‡é‡è¦åº¦è¡¨
    story.append(Paragraph("ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆç¬¬1ä¸»æˆåˆ†ï¼‰", heading_style))
    importance_data = [['ç‰¹å¾´é‡', 'è² è·ç‡', 'çµ¶å¯¾å€¤']]
    for feature, loading in report_data['feature_importance'][:10]:
        importance_data.append([feature, f"{loading:.3f}", f"{abs(loading):.3f}"])

    importance_table = Table(importance_data)
    importance_table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
        ('FONTNAME', (0, 0), (-1, -1), 'HeiseiKakuGo-W5')
    ]))
    story.append(importance_table)

    doc.build(story)
    buffer.seek(0)
    return buffer

def save_figure_as_image(fig):
    """matplotlibã®å›³ã‚’ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    img_buffer = io.BytesIO()
    fig.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
    img_buffer.seek(0)
    return img_buffer

def main():
    # ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±å…¥åŠ›ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.sidebar.header("ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±")
    st.session_state.report_title = st.sidebar.text_input(
        "ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒˆãƒ«",
        value=st.session_state.report_title,
        help="ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )

    st.session_state.author_name = st.sidebar.text_input(
        "ä½œæˆè€…å",
        value=st.session_state.author_name,
        help="ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆè€…åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )

    selected_date = st.sidebar.date_input(
        "åˆ†ææ—¥",
        value=(st.session_state.analysis_date if st.session_state.analysis_date is not None else pd.Timestamp.now().date()),
        help="åˆ†æã‚’å®Ÿè¡Œã—ãŸæ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    st.session_state.analysis_date = selected_date

    st.sidebar.markdown("---")

    st.sidebar.header("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.sidebar.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        help="Labelåˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã¨æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
    )

    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_file.name}' ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("è¡Œæ•°", len(df))
            with col2:
                st.metric("åˆ—æ•°", len(df.columns))
            with col3:
                numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
                st.metric("æ•°å€¤åˆ—", numeric_cols)

            features, labels, feature_columns, label_col = load_and_prepare_data(df)

            if len(feature_columns) < 2:
                st.error("âŒ æ•°å€¤åˆ—ãŒ2ã¤ä»¥ä¸Šå¿…è¦ã§ã™ã€‚")
                return

            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿è©³ç´°")
            col1, col2 = st.columns(2)

            with col1:
                st.write("**ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶:**", features.shape)
                st.write("**ç‰¹å¾´é‡æ•°:**", len(feature_columns))
                if labels is not None:
                    st.write("**ãƒ©ãƒ™ãƒ«åˆ—:**", label_col)
                    st.write("**ãƒ©ãƒ™ãƒ«ç¨®é¡:**", list(np.unique(labels)))

            with col2:
                st.write("**ç‰¹å¾´é‡å:**")
                st.write(feature_columns)

            # ãƒ©ãƒ™ãƒ«ã”ã¨ã®å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
            if labels is not None:
                st.subheader("ğŸ“ˆ ãƒ©ãƒ™ãƒ«ã”ã¨ã®å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«")
                mean_spectrum_fig = create_mean_spectrum_plot(features, labels, feature_columns, label_col)
                if mean_spectrum_fig:
                    st.pyplot(mean_spectrum_fig)

                    # è€ƒå¯Ÿç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹
                    st.markdown("**ğŸ“ ã“ã®ã‚°ãƒ©ãƒ•ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚„çµæœã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:**")
                    st.session_state.mean_spectrum_notes = st.text_area(
                        "å¹³å‡ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ã®è€ƒå¯Ÿ",
                        value=st.session_state.mean_spectrum_notes,
                        height=100,
                        placeholder="ã“ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰åˆ†ã‹ã£ãŸã“ã¨ã€ã‚¯ãƒ©ã‚¹é–“ã®é•ã„ã€ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„..."
                    )
                st.markdown("---")

            st.subheader("ğŸ”¬ PCAåˆ†æå®Ÿè¡Œ")
            with st.spinner("PCAåˆ†æã‚’å®Ÿè¡Œä¸­..."):
                pca_result, pca, explained_variance_ratio = perform_pca_analysis(features)

            st.success("âœ… PCAåˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ç¬¬1ä¸»æˆåˆ†å¯„ä¸ç‡", f"{explained_variance_ratio[0]:.1%}")
            with col2:
                st.metric("ç¬¬2ä¸»æˆåˆ†å¯„ä¸ç‡", f"{explained_variance_ratio[1]:.1%}")
            with col3:
                if len(explained_variance_ratio) > 2:
                    st.metric("ç¬¬3ä¸»æˆåˆ†å¯„ä¸ç‡", f"{explained_variance_ratio[2]:.1%}")
                else:
                    st.metric("ç¬¬3ä¸»æˆåˆ†å¯„ä¸ç‡", "-")
            with col4:
                total_var = sum(explained_variance_ratio[:3]) if len(explained_variance_ratio) >= 3 else sum(explained_variance_ratio[:2])
                st.metric("ç´¯ç©å¯„ä¸ç‡", f"{total_var:.1%}")

            st.subheader("ğŸ“Š åˆ†æçµæœã‚°ãƒ©ãƒ•")

            # ã™ã¹ã¦ã®å›³ã‚’äº‹å‰ç”Ÿæˆï¼ˆPDFå‡ºåŠ›ã«å‚™ãˆã‚‹ï¼‰
            fig_pc12 = create_pca_scatter_plot(pca_result, labels, explained_variance_ratio, dims=(0, 1))
            fig_pc13 = create_pca_scatter_plot(pca_result, labels, explained_variance_ratio, dims=(0, 2)) if pca_result.shape[1] >= 3 else None
            fig_pc23 = create_pca_scatter_plot(pca_result, labels, explained_variance_ratio, dims=(1, 2)) if pca_result.shape[1] >= 3 else None
            loading_fig = create_loading_plot(pca, feature_columns)

            tab1, tab2, tab3, tab4 = st.tabs(["PC1 vs PC2", "PC1 vs PC3", "PC2 vs PC3", "è² è·ç‡ã‚°ãƒ©ãƒ•ï¼ˆPC1/PC2/PC3ï¼‰"])

            with tab1:
                st.pyplot(fig_pc12)

                # PCAæ•£å¸ƒå›³ã®è€ƒå¯Ÿç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹
                st.markdown("**ğŸ“ ã“ã®ã‚°ãƒ©ãƒ•ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚„çµæœã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:**")
                st.session_state.pca_scatter_notes = st.text_area(
                    "PCAæ•£å¸ƒå›³ã®è€ƒå¯Ÿ",
                    value=st.session_state.pca_scatter_notes,
                    height=100,
                    placeholder="ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å½¢æˆã€ã‚µãƒ³ãƒ—ãƒ«é–“ã®é–¢ä¿‚æ€§ã€å¤–ã‚Œå€¤ã®æœ‰ç„¡ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„..."
                )

            with tab2:
                if fig_pc13 is not None:
                    st.pyplot(fig_pc13)
                else:
                    st.info("PC3ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€ã“ã®ã‚°ãƒ©ãƒ•ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

                st.markdown("**ğŸ“ ã“ã®ã‚°ãƒ©ãƒ•ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚„çµæœã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:**")
                st.session_state.pca_scatter_notes = st.text_area(
                    "PCAæ•£å¸ƒå›³ã®è€ƒå¯Ÿ (PC1 vs PC3)",
                    value=st.session_state.pca_scatter_notes,
                    height=100,
                    placeholder="ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å½¢æˆã€ã‚µãƒ³ãƒ—ãƒ«é–“ã®é–¢ä¿‚æ€§ã€å¤–ã‚Œå€¤ã®æœ‰ç„¡ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„..."
                )

            with tab3:
                if fig_pc23 is not None:
                    st.pyplot(fig_pc23)
                else:
                    st.info("PC3ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€ã“ã®ã‚°ãƒ©ãƒ•ã¯è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

                st.markdown("**ğŸ“ ã“ã®ã‚°ãƒ©ãƒ•ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚„çµæœã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:**")
                st.session_state.pca_scatter_notes = st.text_area(
                    "PCAæ•£å¸ƒå›³ã®è€ƒå¯Ÿ (PC2 vs PC3)",
                    value=st.session_state.pca_scatter_notes,
                    height=100,
                    placeholder="ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®å½¢æˆã€ã‚µãƒ³ãƒ—ãƒ«é–“ã®é–¢ä¿‚æ€§ã€å¤–ã‚Œå€¤ã®æœ‰ç„¡ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„..."
                )

            with tab4:
                st.markdown("#### PC1 è² è·ç‡")
                st.pyplot(create_loading_plot(pca, feature_columns, pc_index=0))
                st.markdown("#### PC2 è² è·ç‡")
                st.pyplot(create_loading_plot(pca, feature_columns, pc_index=1))
                if pca.n_components_ >= 3:
                    st.markdown("#### PC3 è² è·ç‡")
                    st.pyplot(create_loading_plot(pca, feature_columns, pc_index=2))

                # è² è·ç‡ã‚°ãƒ©ãƒ•ã®è€ƒå¯Ÿç”¨ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹
                st.markdown("**ğŸ“ ã“ã®ã‚°ãƒ©ãƒ•ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚„çµæœã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:**")
                st.session_state.loading_notes = st.text_area(
                    "è² è·ç‡ã‚°ãƒ©ãƒ•ã®è€ƒå¯Ÿ",
                    value=st.session_state.loading_notes,
                    height=100,
                    placeholder="é‡è¦ãªç‰¹å¾´é‡ã€æ­£è² ã®ç›¸é–¢ã€ç‰¹å¾´é‡ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„..."
                )

            st.subheader("ğŸ“ˆ è©³ç´°åˆ†æçµæœ")

            pc1_loadings = pca.components_[0]
            feature_importance = list(zip(feature_columns, pc1_loadings))
            feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)

            st.write("**ç¬¬1ä¸»æˆåˆ†ã¸ã®å¯„ä¸åº¦ä¸Šä½10ç‰¹å¾´é‡:**")
            importance_df = pd.DataFrame(feature_importance[:10], columns=['ç‰¹å¾´é‡', 'è² è·ç‡'])
            importance_df['çµ¶å¯¾å€¤'] = importance_df['è² è·ç‡'].abs()
            importance_df = importance_df.sort_values('çµ¶å¯¾å€¤', ascending=False)
            st.dataframe(importance_df, use_container_width=True)

            # ç·åˆè€ƒå¯Ÿã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.subheader("ğŸ“ ç·åˆè€ƒå¯Ÿ")
            st.markdown("**åˆ†æå…¨ä½“ã‚’é€šã˜ã¦ã®ç·åˆçš„ãªè€ƒå¯Ÿã‚„çµè«–ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„:**")
            st.session_state.overall_conclusion = st.text_area(
                "ç·åˆè€ƒå¯Ÿ",
                value=st.session_state.overall_conclusion,
                height=150,
                placeholder="PCAåˆ†æã®çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå…¨ä½“çš„ãªçŸ¥è¦‹ã€å®Ÿç”¨çš„ãªæ„å‘³ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„..."
            )

            st.subheader("ğŸ’¾ çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

            col1, col2 = st.columns(2)

            with col1:
                # PC1-3 ã‚’å‡ºåŠ›
                pc_cols = ['PC1', 'PC2', 'PC3'] if pca_result.shape[1] >= 3 else ['PC1', 'PC2']
                pca_df = pd.DataFrame(pca_result[:, :len(pc_cols)], columns=pc_cols)
                if labels is not None:
                    pca_df['Label'] = labels

                csv_buffer = io.StringIO()
                pca_df.to_csv(csv_buffer, index=False)
                st.download_button(
                    label="PCAçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
                    data=csv_buffer.getvalue(),
                    file_name="pca_results.csv",
                    mime="text/csv"
                )

            with col2:
                # PDFãƒ¬ãƒãƒ¼ãƒˆä½œæˆãƒœã‚¿ãƒ³
                if st.button("ğŸ“„ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ", type="primary"):
                    with st.spinner("PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆä¸­..."):
                        try:
                            # å›³ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜
                            mean_spectrum_img = save_figure_as_image(mean_spectrum_fig) if labels is not None else None
                            pca_scatter_img = save_figure_as_image(fig_pc12)
                            pca_scatter_img_pc13 = save_figure_as_image(fig_pc13) if fig_pc13 is not None else None
                            pca_scatter_img_pc23 = save_figure_as_image(fig_pc23) if fig_pc23 is not None else None
                            loading_img_pc1 = save_figure_as_image(create_loading_plot(pca, feature_columns, pc_index=0))
                            loading_img_pc2 = save_figure_as_image(create_loading_plot(pca, feature_columns, pc_index=1))
                            loading_img_pc3 = save_figure_as_image(create_loading_plot(pca, feature_columns, pc_index=2)) if pca.n_components_ >= 3 else None

                            # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
                            report_data = {
                                'title': st.session_state.report_title,
                                'author': st.session_state.author_name,
                                'date': (st.session_state.analysis_date.strftime("%Yå¹´%mæœˆ%dæ—¥") if st.session_state.analysis_date else ""),
                                'data_shape': f"{features.shape[0]}è¡Œ Ã— {features.shape[1]}åˆ—",
                                'feature_count': len(feature_columns),
                                'label_info': f"{label_col}: {list(np.unique(labels))}" if labels is not None else "ãªã—",
                                'pc1_variance': explained_variance_ratio[0],
                                'pc2_variance': explained_variance_ratio[1],
                                'total_variance': sum(explained_variance_ratio[:3]) if len(explained_variance_ratio) >= 3 else sum(explained_variance_ratio[:2]),
                                'pc3_variance': (explained_variance_ratio[2] if len(explained_variance_ratio) >= 3 else None),
                                'mean_spectrum_fig': mean_spectrum_img,
                                'pca_scatter_fig': pca_scatter_img,
                                'pca_scatter_fig_pc13': pca_scatter_img_pc13,
                                'pca_scatter_fig_pc23': pca_scatter_img_pc23,
                                'loading_fig': loading_img_pc1,
                                'loading_fig_pc2': loading_img_pc2,
                                'loading_fig_pc3': loading_img_pc3,
                                'mean_spectrum_notes': st.session_state.mean_spectrum_notes,
                                'pca_scatter_notes': st.session_state.pca_scatter_notes,
                                'loading_notes': st.session_state.loading_notes,
                                'overall_conclusion': st.session_state.overall_conclusion,
                                'feature_importance': feature_importance[:10]
                            }

                            # PDFãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
                            pdf_buffer = create_pdf_report(report_data)

                            # PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            st.download_button(
                                label="ğŸ“¥ PDFãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=pdf_buffer.getvalue(),
                                file_name=f"PCA_analysis_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                                mime="application/pdf"
                            )

                            st.success("âœ… PDFãƒ¬ãƒãƒ¼ãƒˆãŒä½œæˆã•ã‚Œã¾ã—ãŸï¼")

                        except Exception as e:
                            st.error(f"âŒ PDFãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.write("ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    else:
        st.info("ğŸ‘† å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

        st.markdown("""
        ### ğŸ“‹ å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼

        **CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è¦ä»¶:**
        - æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åˆ—ãŒ2ã¤ä»¥ä¸Šå¿…è¦ã§ã™
        - ãƒ©ãƒ™ãƒ«åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰: 'Label', 'Class', 'Category', 'Group' ãªã©ã®åå‰

        **ä¾‹:**
        ```csv
        Label,feature1,feature2,feature3
        A,1.2,3.4,5.6
        B,2.1,4.3,6.5
        C,1.8,3.9,5.2
        ```
        """)

        st.markdown("### ğŸ“¥ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
        sample_data = pd.DataFrame({
            'Label': ['A', 'A', 'B', 'B', 'C', 'C'] * 3,
            'feature1': np.random.randn(18),
            'feature2': np.random.randn(18),
            'feature3': np.random.randn(18),
            'feature4': np.random.randn(18)
        })

        csv_buffer = io.StringIO()
        sample_data.to_csv(csv_buffer, index=False)
        st.download_button(
            label="ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_buffer.getvalue(),
            file_name="sample_data.csv",
            mime="text/csv"
        )

if __name__ == "__main__":
    main()
